{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55.dev0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.vision.interpret import *\n",
    "import fastai; fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../../data/siim_acr_pneu/train'),\n",
       " PosixPath('../../data/siim_acr_pneu/clas_df.csv'),\n",
       " PosixPath('../../data/siim_acr_pneu/dicom-images-test'),\n",
       " PosixPath('../../data/siim_acr_pneu/models'),\n",
       " PosixPath('../../data/siim_acr_pneu/dicom-images-train'),\n",
       " PosixPath('../../data/siim_acr_pneu/train-rle.csv'),\n",
       " PosixPath('../../data/siim_acr_pneu/seg_df.csv'),\n",
       " PosixPath('../../data/siim_acr_pneu/learn'),\n",
       " PosixPath('../../data/siim_acr_pneu/test')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"../../data/siim_acr_pneu/\"); data_path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_functions import *\n",
    "from skimage.measure import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow\n",
    "\n",
    "- 1) Run segmentation on all valid and test images\n",
    "- 2) Run classification on all test valid and images\n",
    "- 3) Find optimal thresh\n",
    "- 4) Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed or div=False\n",
    "class SegmentationLabelList(SegmentationLabelList):\n",
    "    def open(self, fn): return open_mask(fn, div=True)\n",
    "\n",
    "class SegmentationItemList(SegmentationItemList):\n",
    "    _label_cls = SegmentationLabelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_learn = Learner(**torch.load(data_path/f'learn/clas-chexpert-ft-resnext34-{sz}'))\n",
    "seg_learn = Learner(**torch.load(data_path/f'learn/seg-chexpert-ft-resnext34-{sz}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Run seg on valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_valid_probs, seg_valid_targs = seg_learn.get_preds(DatasetType.Valid)\n",
    "seg_test_probs, seg_test_targs = seg_learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Semantic Dice (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_dice(input, target, t):\n",
    "    '''\n",
    "    semantic dice score with threshold \n",
    "    input: 1 mask probability per image\n",
    "    target: 1 mask target per image\n",
    "    '''\n",
    "    input_hard = input[:,1,:,:] > t\n",
    "    n = input_hard.shape[0]\n",
    "    inputs = input_hard.float().view(n,-1)\n",
    "    targs = target.float().view(n,-1)\n",
    "    intersect = (inputs * targs).sum()\n",
    "    union = (inputs+targs).sum()\n",
    "    dice = ((2. * intersect) / union)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # dice scores at different probability thresholds\n",
    "# for t in np.linspace(0,1,21):\n",
    "#     d = semantic_dice(seg_valid_probs, seg_valid_targs, t=t)\n",
    "#     print(t, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Instance Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rles for each validation image\n",
    "train_rle_df = pd.read_csv(data_path/'train-rle.csv')\n",
    "valid_image_ids = [Path(o).stem for o in seg_learn.data.valid_ds.items]\n",
    "valid_rle_dict = {o:train_rle_df[train_rle_df.ImageId == o][' EncodedPixels'].values for o in valid_image_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rles2masks(rles):\n",
    "    'convert rles into list of (1024,1024) binary (0,1) masks'\n",
    "    masks = []\n",
    "    for rle in rles:\n",
    "        maskimg = PIL.Image.fromarray(rle2mask(rle, 1024, 1024).T.astype(np.uint8))\n",
    "        assert np.all(np.unique(np.asarray(maskimg)) == np.array([0,255]))\n",
    "        masks.append((np.asarray(maskimg)/255).astype(np.uint8))\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create masks for all validation images\n",
    "valid_instance_targs = [np.array(rles2masks(valid_rle_dict[k])) for k in valid_image_ids]\n",
    "len(valid_instance_targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "masks = valid_instance_targs[0]\n",
    "for m in masks: assert np.all(np.unique(m) == np.array([0,1]))\n",
    "plt.imshow(np.concatenate(masks));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1377, 2, 224, 224])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_test_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob2preds(prob, t):\n",
    "    '''\n",
    "    create instance preds from single mask probs \n",
    "    '''\n",
    "    input_hard = prob[1,:,:] > t\n",
    "    label_image = label(input_hard)\n",
    "    unique_labels = np.unique(label_image)[1:]\n",
    "    if len(unique_labels) > 0:\n",
    "        instance_preds = [(label_image == l).astype(np.uint8) for l in unique_labels]\n",
    "        instance_preds_resized = [np.asarray(PIL.Image.fromarray(arr).resize((1024,1024), \n",
    "                                    resample=PIL.Image.NEAREST)) for arr in instance_preds]\n",
    "    else: instance_preds_resized = '-1'\n",
    "    return np.array(instance_preds_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.5\n",
    "valid_instance_preds = [prob2preds(prob, t) for prob in seg_valid_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "masks = valid_instance_preds[0]\n",
    "for m in masks: assert np.all(np.unique(m) == np.array([0,1]))\n",
    "plt.imshow(np.concatenate(masks));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def instance_dice(instance_preds, instance_targs):\n",
    "    '''\n",
    "    instance dice score with threshold \n",
    "    instance_preds: list of N_i mask (0,1) per image\n",
    "    instance_targs: list of M_i mask (0,1) target per image\n",
    "    '''\n",
    "    \n",
    "#     # for plotting\n",
    "#     fig,axes=plt.subplots(1,2)\n",
    "#     axes[0].imshow(np.concatenate(valid_instance_targs[i]))\n",
    "#     axes[1].imshow(np.concatenate(valid_instance_preds[i]))\n",
    "    \n",
    "    scores = []\n",
    "    for i in (range(len(instance_preds))):\n",
    "        if np.all(valid_instance_preds[i] == np.array(['-1'])): scores.append(0)\n",
    "        else:\n",
    "            m,_,_ = valid_instance_targs[i].shape\n",
    "            n,_,_ = valid_instance_preds[i].shape\n",
    "\n",
    "            targs = valid_instance_targs[i].reshape(m,-1)\n",
    "            preds = valid_instance_preds[i].reshape(n,-1)\n",
    "\n",
    "            # intersect: matrix of targ x preds (M, N)\n",
    "            intersect = ((targs[:,None,:]*preds[None,:,:]) > 0).sum(2)    \n",
    "            targs_area, preds_area = targs.sum(1), preds.sum(1)\n",
    "            union = targs_area[:, None] + preds_area[None,:]\n",
    "\n",
    "            dice = (2*intersect / union); dice\n",
    "            dice_scores = dice[linear_sum_assignment(1-dice)]\n",
    "            mean_dice_score = sum(dice_scores) / max(n, m) # unmatched gt or preds are counted as 0\n",
    "            scores.append(mean_dice_score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb9665c38be4c65b3869601c70b3182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/turgutluk/.conda/envs/my_fastai/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "# at t = 0.5\n",
    "best_dice, best_seg_thres = 0, None\n",
    "\n",
    "for t in tqdm_notebook(np.linspace(0,1,21)):\n",
    "    valid_instance_preds = [prob2preds(prob, t) for prob in seg_valid_probs]\n",
    "    dice_score = np.mean(instance_dice(valid_instance_preds, valid_instance_targs))\n",
    "    if dice_score > best_dice: best_dice, best_seg_thres= dice_score, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3186035988035392, 0.30000000000000004)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dice, best_seg_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run clas on valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_valid_probs, clas_valid_targs = clas_learn.get_preds(DatasetType.Valid)\n",
    "clas_test_probs, clas_test_targs = clas_learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Grid search for best thres -  Calculate approx LB score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thres(best_dice=best_dice, best_seg_thres=best_seg_thres):\n",
    "    \"grid search cls_thres, seg_thres\"\n",
    "    best_score, best_cls_thres = 0, None\n",
    "    \n",
    "    for cls_thres in np.linspace(0,1,21):\n",
    "        clas_valid_hard = clas_valid_probs[:, 1] > cls_thres\n",
    "        cm = confusion_matrix(clas_valid_targs, clas_valid_hard)\n",
    "\n",
    "        P_0_0 = cm[0,0] / cm[0, :].sum()\n",
    "        P_1_1 = cm[1,1] / cm[1, :].sum()\n",
    "\n",
    "        # public LB ratios\n",
    "        R_1, R_0 = 0.7886, 0.2114\n",
    "        score_cls, score_seg = R_1*P_1_1, R_0*P_0_0*best_dice\n",
    "        total = score_cls + score_seg\n",
    "\n",
    "        # update\n",
    "        if total > best_score:\n",
    "            best_score, best_cls_thres  = total, cls_thres\n",
    "\n",
    "    return best_score, best_cls_thres, best_seg_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score, best_cls_thres, best_seg_thres = find_best_thres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8016543733499933, 0.15000000000000002, 0.30000000000000004)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score, best_cls_thres, best_seg_thres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Submit\n",
    "\n",
    "- Convert segmentation probas to binary \n",
    "- Resize to 1024, 1024\n",
    "- Separate instances\n",
    "- Convert individual masks to rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_thres, seg_thres = best_cls_thres, best_seg_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1377, 224, 224])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert all soft mask predictions to hard predictions\n",
    "seg_test_hard = (seg_test_probs[:,1,:,:] > seg_thres).squeeze(1); seg_test_hard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAADgCAYAAAAaLWrhAAAABHNCSVQICAgIfAhkiAAAA7RJREFUeJzt3d1NG0EYQFETpQqqoIhINJBm6YIqaCN5iSXHwv9r3/XMOa8sMKz27jcLtnj59fL7zwZI/KgXADMTIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECKGf9QJG9PH1efKY99e3B6yEtRPgQs6Jbv94EWILuoBL47v18xiHAG/w8fV5c0QinJsAr7BEePtfjzl5BryAUFiaCQghAZ5h6S3noe9RW8MaZiPAE2a7KHd/3u2NZ7Zz8EieAY+Y6cLbD4/HMAEPcBH+z/m4DwF+w8X2PedleQJcCS9Lm5NnwD2z3uX3bwDfnYfdY7Yfd+O4jQB3zBrfMYcCE94yBPhPGd8aL+Y1rmlEngEhJMCN6UfHFjQiPDYbEzCZfuJja/oAH0187Jo6QH92oDZtgLaerIFfwjyA8DhkygCXnH7i4hbTbUGXiO/99U14LGLKCXgt0bG0qQK8dvp5QTL3Mt0W9FIi456mCfCa6Sc+7m2KLeil8QmPR5kiwHMJj0cbfgt67vQTH4XhAzyH+KgMHaD/VMvaDR3gKeKjNmyAp6af+FiDIQP0Pj+exZABnmL6sRbDBWjryTMZLsBjxMfaDBXgseknPtZoqAAPER9rNXyA4mPNhg5QfKzd0AHC2g0boOnHMxgyQPHxLIYMEJ7FUO+IN/l4NiYghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIIQFCSIAQEiCEBAghAUJIgBASIIQECCEBQkiAEBIghAQIob9Fs49/RuM+owAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "ImageSegment (1, 224, 224)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageSegment(seg_test_hard[4][None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2pil(t):\n",
    "    return (PIL.Image.fromarray((to_np(t)*255).astype(np.uint8), mode='L')\n",
    "                .resize((1024,1024), PIL.Image.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskarray2rles(maskarray):\n",
    "    rles = []\n",
    "    labeled_maskarray = label(maskarray)\n",
    "    unique_labels = list(np.unique(labeled_maskarray)[1:])\n",
    "    for l in unique_labels:\n",
    "        rle = mask2rle((labeled_maskarray == l).astype(np.uint8)*255, *(1024,1024))\n",
    "        rles.append(rle)\n",
    "    return rles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract test image ids\n",
    "test_image_ids = np.array([o.stem for o in seg_learn.data.test_ds.items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find images to submit mask predictions for\n",
    "has_pneumo = to_np((clas_test_probs[:, 1] < cls_thres)).astype(bool)\n",
    "\n",
    "mask_test_image_ids = test_image_ids[has_pneumo]\n",
    "mask_test_hard = seg_test_hard[tensor(has_pneumo)]\n",
    "\n",
    "no_mask_test_image_ids = test_image_ids[~has_pneumo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132,), (1245,), torch.Size([132, 224, 224]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_test_image_ids.shape, no_mask_test_image_ids.shape, mask_test_hard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60837e8118af4fb5b036cc6d154d6e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create rle for all test predictions\n",
    "all_image_ids = []\n",
    "all_rles = []\n",
    "for i in tqdm_notebook(range(len(mask_test_image_ids))):    \n",
    "    image_id, t = mask_test_image_ids[i], mask_test_hard[i]\n",
    "    maskimg = tensor2pil(t)\n",
    "    maskarray = np.asarray(maskimg).T\n",
    "    if len(np.unique(maskarray)) != 1: rles = maskarray2rles(maskarray)\n",
    "    else: rles = ['-1']\n",
    "    for rle in rles:\n",
    "        all_image_ids.append(image_id)\n",
    "        all_rles.append(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 283)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_image_ids), len(all_rles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame({\"ImageId\": all_image_ids, \"EncodedPixels\":all_rles})\n",
    "sub2 = pd.DataFrame({\"ImageId\": no_mask_test_image_ids, \"EncodedPixels\":\"-1\"})\n",
    "\n",
    "final_sub = pd.concat([sub1, sub2])\n",
    "final_sub.to_csv(\"sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub2 = pd.DataFrame({\"ImageId\": no_mask_test_image_ids, \"EncodedPixels\":\"-1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = pd.concat([sub1, sub2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub.to_csv(\"sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sub.csv' target='_blank'>sub.csv</a><br>"
      ],
      "text/plain": [
       "/home/turgutluk/git/siim_acr_pneu/sub.csv"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(\"sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_fastai]",
   "language": "python",
   "name": "conda-env-my_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
